name: Deploy inference application

on:
  #push:
  #  branches:
  #    - main
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v3
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}
      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Retrieve EC2 Instance IDs and IP addresses
        id: get_instance_id
        run: |
          INSTANCE_ID_STAGING=$(aws cloudformation describe-stacks \
            --stack-name ec2-deployment-stack-staging \
            --query "Stacks[0].Outputs[?OutputKey=='InstanceId'].OutputValue" \
            --output text)
          PUBLIC_IP_STAGING=$(aws ec2 describe-instances \
            --instance-ids $INSTANCE_ID_STAGING \
            --query "Reservations[0].Instances[0].PublicIpAddress" \
            --output text)
          INSTANCE_ID_PROD=$(aws cloudformation describe-stacks \
            --stack-name ec2-deployment-stack-prod \
            --query "Stacks[0].Outputs[?OutputKey=='InstanceId'].OutputValue" \
            --output text)
          PUBLIC_IP_PROD=$(aws ec2 describe-instances \
            --instance-ids $INSTANCE_ID_PROD \
            --query "Reservations[0].Instances[0].PublicIpAddress" \
            --output text)
          echo "PUBLIC_IP_STAGING=$PUBLIC_IP_STAGING" >> $GITHUB_ENV
          echo "PUBLIC_IP_PROD=$PUBLIC_IP_PROD" >> $GITHUB_ENV


      - name: Set up SSH key
        env:
          SSH_PRIVATE_KEY: ${{ secrets.EC2_SSH_KEY }}
        run: |
          echo "$SSH_PRIVATE_KEY" > ssh_key
          chmod 600 ssh_key
    
      - name: Deploy to staging
        env:
          HOST: ${{ env.PUBLIC_IP_STAGING }}
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          INFERENCE_ECR_REPOSITORY: bert/inference
          USERNAME: ubuntu
        run: |
          LATEST_INFERENCE_IMAGE=$ECR_REGISTRY/$INFERENCE_ECR_REPOSITORY:latest
          ssh -i ssh_key -o StrictHostKeyChecking=no $USERNAME@$HOST '
            sudo aws ecr get-login-password --region us-east-1 | sudo docker login --username AWS --password-stdin $ECR_REGISTRY
            sudo docker pull $LATEST_INFERENCE_IMAGE
            sudo docker run -d --rm --name bert_smoketest -p 8000:8000 $LATEST_INFERENCE_IMAGE
            ' 
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install boto3 sagemaker mlflow==2.16.2 sagemaker-mlflow==0.1.0 requests
      
      - name: Perform smoke testing
        env:
            HOST: ${{ env.PUBLIC_IP_STAGING }}
            MLFLOW_TRACKING_SERVER_ARN: ${{ secrets.MLFLOW_TRACKING_SERVER_ARN }}
            EC2_INSTANCE_ID: $INSTANCE_ID_STAGING
            MODEL_NAME: "bert-genre-classifier"
            USERNAME: ubuntu
        run: |
          python infer/tests/smoke_test.py
      
      - name: Clean up Staging Container
        if: always()
        env:
          HOST: ${{ env.PUBLIC_IP_STAGING }}
          USERNAME: ubuntu
        run: |
          echo "Cleaning up the smoke test container on staging..."
          ssh -i ssh_key -o StrictHostKeyChecking=no $USERNAME@$HOST '
            sudo docker stop bert_smoketest || true
            '
      
      - name: Alias model to become champion
        env:
          MLFLOW_TRACKING_SERVER_ARN: ${{ secrets.MLFLOW_TRACKING_SERVER_ARN }}
        run: |
          python .github/scripts/model_aliasing.py --model_name bert-genre-classifier --alias champion

      - name: Deploy to production
        env:
          HOST: ${{ env.PUBLIC_IP_PROD }}
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          INFERENCE_ECR_REPOSITORY: bert/inference
          MODEL_NAME: "bert-genre-classifier"
          USERNAME: ubuntu
        run: |
          ssh -i ssh_key -o StrictHostKeyChecking=no $USERNAME@$HOST '
            sudo aws ecr get-login-password --region us-east-1 | sudo docker login --username AWS --password-stdin $ECR_REGISTRY
            sudo docker pull $LATEST_INFERENCE_IMAGE
            sudo docker run -d --rm --name bert_smoketest -p 8000:8000 $LATEST_INFERENCE_IMAGE
            '  
